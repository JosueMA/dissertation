# Results

```{r read-results}
rec_results  <- read_rds("data/sim-recovery.rds")
full_results <- read_rds("data/sim-allreps.rds")

rec_results <- rec_results %>%
  ungroup() %>%
  mutate(
    cond = factor(cond),
    attributes = factor(attributes, levels = c(3, 4), labels = c("3 Attributes",
      "4 Attributes")),
    sample_size = factor(sample_size),
    over_spec = factor(over_spec, levels = c(0, 0.1, 0.2),
      labels = c("Over Specification:\n0.0", "Over Specification:\n0.1",
        "Over Specification:\n0.2")),
    model = factor(model, levels = c("satr", "siml", "meas", "strc",
      "meas-strc", "strc-meas"), labels = c("Saturated", "Simultaneous",
        "Measurement", "Structural", "Measurement-Structural",
        "Structural-Measurement"))
  )
```

Results from the simulation study are described in two sections. Section \@ref(pval-results) summarizes the performance of the reduction processes when the parameters to reduce were determined by p-values from a converged model (i.e., p-value/p-value reduction). Section \@ref(heur-results) summarizes results of the reduction processes a model did not converge, and the parameters to reduce were determined by the higher order interaction heuristic (i.e., heuristic/p-value reduction).

Table \@ref(tab:satr-converge) shows the convergence rates for the saturated model. As expected, the convergence rates decrease as the number of attributes increases, and decrease dramatically as the over specification of the Q-matrix increases. Interestingly, sample size had relatively little effect on the convergence rates of the saturated model, with rates staying fairly consistent with attribute and over specification conditions.

```{r satr-converge}
satr_con <- full_results %>%
  filter(model == "satr") %>%
  group_by(attributes, sample_size, over_spec) %>%
  summarize(convergence_rate = mean(converge)) %>%
  mutate(col_label = map2_chr(attributes, sample_size, function(x, y) {
    paste0(x, "_", y)
  })) %>%
  ungroup() %>%
  select(over_spec, col_label, convergence_rate) %>%
  spread(key = col_label, value = convergence_rate) %>%
  select(over_spec, `3_500`, `3_1000`, `3_5000`, `4_500`, `4_1000`, `4_5000`)

colnames(satr_con) <- c("Q-Matrix Over Specification", "n = 500", "n = 1000",
  "n = 5000", "n = 500", "n = 1000", "n = 5000")

knitr::kable(satr_con, align = "c", booktabs = TRUE,
  caption = "Saturated model convergence rates", format = knit_format) %>%
  kable_styling(latex_options = "hold_position") %>%
  add_header_above(c(" " = 1, "3 Attributes" = 3, "4 Attributes" = 3))
```

## Reduction by p-value {#pval-results}

```{r format-reps}
full_results <- full_results %>%
  ungroup() %>%
  mutate(
    cond = factor(cond),
    attributes = factor(attributes, levels = c(3, 4), labels = c("3 Attributes",
      "4 Attributes")),
    sample_size = factor(sample_size),
    over_spec = factor(over_spec, levels = c(0, 0.1, 0.2),
      labels = c("Over Specification:\n0.0", "Over Specification:\n0.1",
        "Over Specification:\n0.2")),
    model = factor(model, levels = c("satr", "siml", "meas", "strc",
      "meas-strc", "strc-meas"), labels = c("Saturated", "Simultaneous",
        "Measurement", "Structural", "Measurement-Structural",
        "Structural-Measurement"))
  )
```


### Convergence

When saturated model converged, reduction of measurement and structural parameters proceeded by using p-values to determine which parameters to reduce. Figure \@ref(fig:pvalue-converge) shows the convergence rates for these reduction processes when. Recall that measurement-structural and structural measurement reduction only occured if the measurement and strucutral reductions, respectively, converged. Across all conditions, reduction processes where there measurment model was reduced first (i.e., simultaneous, measurment, and measurement-structural) tended to have higher convergence rates. This most notable when the Q-matrix was overspecified. In the most extreme case, the four-attribute condition with a 20 percent over specified Q-matrix, no reductions converged if the measurement model was not part of the initial reduction. However, because the saturated model very rarely converged for this condition (Table \@ref(tab:satr-converge)), the sample size is very limited.

```{r pvalue-converge, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Convergence rates when reducing using p-values", fig.pos = "h"}
p <- rec_results %>% 
  filter(satr_converge == TRUE) %>%
  ggplot(aes(x = sample_size, y = converge, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Convergence Rate", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-converge.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-converge.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-converge.pdf")
} else {
  knitr::include_graphics("figure/pvalue-converge.png")
}
```

### Parameter Recovery

To evaluate the performance of the reduction processes, the bias and mean square error of the parameter estimates can be examined. The bias represents the difference between the true value and the estimated value. The mean square error represents the average of the squared difference between the true and estimated values. Figure \@ref(fig:pvalue-bias) and Figure \@ref(fig:pvalue-mse) show the total bias and total mean square error, respectively, across all measurement model parameters when reducing using p-values. Because of some outlying data sets, biases with an absolute value greater than 100 and mean square errors with a value greater than 100 have been excluded from the figures. Figures showing all biases and mean square errors, separated by the type of parameter can be seen in Appendix \@ref(app-param-recov).

```{r pvalue-bias, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Bias in measurement model main effect estimates when reducing using p-values", fig.pos = "h"}
p <- rec_results %>% 
  filter(satr_converge == TRUE) %>%
  mutate(
    total_bias = pmap_dbl(list(intercept_bias, main_effect_bias,
      interaction2_bias, interaction3_bias, interaction4_bias),
      function(x1, x2, x3, x4, x5) {
        sum(x1, x2, x3, x4, x5, na.rm = TRUE)
      })
  ) %>%
  filter(abs(total_bias) < 100) %>%
  ggplot(aes(x = sample_size, y = total_bias, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Average Bias", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-bias.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-bias.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-bias.pdf")
} else {
  knitr::include_graphics("figure/pvalue-bias.png")
}
```

```{r pvalue-mse, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Mean square error in measurement model main effect estimates when reducing using p-values", fig.pos = "h"}
p <- rec_results %>% 
  filter(satr_converge == TRUE) %>%
  mutate(
    total_mse = pmap_dbl(list(intercept_mse, main_effect_mse,
      interaction2_mse, interaction3_mse, interaction4_mse),
      function(x1, x2, x3, x4, x5) {
        sum(x1, x2, x3, x4, x5, na.rm = TRUE)
      })
  ) %>%
  mutate(total_mse = case_when(total_mse <= 100 ~ total_mse, TRUE ~ NA_real_)) %>%
  ggplot(aes(x = sample_size, y = total_mse, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Average Mean Square Error", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-mse.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-mse.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-mse.pdf")
} else {
  knitr::include_graphics("figure/pvalue-mse.png")
}
```

Figure \@ref(fig:pvalue-bias) shows that across all conditions there is relatively little bias in the measurement model parameters. This is especially true when the Q-matrix is correctly specified. The large negative bias seen in the measurement reduction condition for the three attribute and 10 percent over specified Q-matrix is due to a single three way interaction in one data set, as can be seen in Figure \@ref(fig:pvalue-int3-bias). In contrast, there is relatively large mean square error values across conditions. As expected, this decreases as the sample size increases. Thus, these results suggest that larger sample sizes (i.e., greater than 1,000) are needed in order to ensure unbiased estimates of measurement model parameters with low levels of error.

Figure \@ref(fig:pvalue-strc-bias) and Figure \@ref(fig:pvalue-strc-mse) show the bias and mean square error of the structural parameters respectively. Overall, there is very little bias and mean squared error in the structural parameters. The instances where larger bias and mean squared error are indicated (e.g., measurement reduction of a four attribute model with a 20% over specified Q-matrix) are instances where very few of the model actually converged. Thus, these values are based on only a few replications. Thus, these results suggests that given model convergence, the structural parameters are usually well estimated regardless of model reduction method.

```{r pvalue-strc-bias, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Bias in structrual model parameter estimates when reducing using p-values", fig.pos = "h"}
p <- rec_results %>%
  filter(satr_converge == TRUE) %>%
  mutate(structural_bias = case_when(structural_bias <= 100 ~ structural_bias,
    TRUE ~ NA_real_)) %>%
  ggplot(aes(x = sample_size, y = structural_bias, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Average Bias", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-strc-bias.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-strc-bias.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-strc-bias.pdf")
} else {
  knitr::include_graphics("figure/pvalue-strc-bias.png")
}
```

```{r pvalue-strc-mse, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Mean square error in structrual model parameter estimates when reducing using p-values", fig.pos = "h"}
p <- rec_results %>%
  filter(satr_converge == TRUE) %>%
  mutate(structural_mse = case_when(structural_mse <= 100 ~ structural_mse,
    TRUE ~ NA_real_)) %>%
  ggplot(aes(x = sample_size, y = structural_mse, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Average Mean Square Error", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-strc-mse.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-strc-mse.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-strc-mse.pdf")
} else {
  knitr::include_graphics("figure/pvalue-strc-mse.png")
}
```

### Mastery Classification

Another critical measure of performance is the rate at which respondents are correctly classified as masters of the attributes. This is assessed at two levels: the individual attribute classifications, and the overall profile classification. As described in section \@ref(method-outcome), profile mastery and attribute mastery differentiate between two types of assignments that can occur. For example, a respondent may have a true profile of [1,0,1,0] and an estimated profile of [1,1,1,0]. Here, the overall profile assignment is incorrect (profile classification), but three out of the four individual attributes are correctly classified (attribute classification). Respondents were classified as a master of an attribute if their posterior probability of mastery was greater than or equal to .5, and non-master of the attribute otherwise. Figure \@ref(fig:pvalue-attr-ccr) and Figure \@ref(fig:pvalue-attr-kap) show the attribute level agreement as measured by the average correct classification rate and average Cohen's $\kappa$, respectively.

(ref:pvalue-kap-attr) Average Cohen's $\kappa$ of attribute mastery when reducing using p-values

(ref:pvalue-kap-prof) Average Cohen's $\kappa$ of profile assignment when reducing using p-values

```{r pvalue-attr-ccr, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Average correct classification rate of attribute mastery when reducing using p-values", fig.pos = "h"}
p <- rec_results %>%
  filter(satr_converge == TRUE) %>%
  ggplot(aes(x = sample_size, y = attribute_ccr, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Attribute Correct Classification Rate", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-attr-ccr.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-attr-ccr.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-attr-ccr.pdf")
} else {
  knitr::include_graphics("figure/pvalue-attr-ccr.png")
}
```

```{r pvalue-attr-kap, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "(ref:pvalue-kap-attr)", fig.pos = "h"}
p <- rec_results %>%
  filter(satr_converge == TRUE) %>%
  ggplot(aes(x = sample_size, y = attribute_kappa, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = expression("Average Attribute Cohen's "*kappa), fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-attr-kap.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-attr-kap.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-attr-kap.pdf")
} else {
  knitr::include_graphics("figure/pvalue-attr-kap.png")
}
```

Across all conditions, both the correct classification rate and Cohen's $\kappa$ show high rates of agreement between true and estimated attribute classifications. The exception is a four-attribute assessment with a sample size of only 500. Under these conditions, all model reduction processes showed lower rates of agreement than with larger samples or only three attributes.

The overall profile classification shows a similar pattern. Figure \@ref(fig:pvalue-prof-ccr) and Figure \@ref(fig:pvalue-prof-kap) show the correct classificaiton rate and Cohen's $\kappa$ of the overall profiles. As expected, the overall profile agreement is consistently lower than the attribute level mastery classification agreement, although the classification agreement is generally consistent across all model reduction processes. Additionally, as with the attribute classifications, profile classification agreement was lower in the four-attriubte, 500 sample size conditions.

```{r pvalue-prof-ccr, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Average correct classification rate of profile assignment when reducing using p-values", fig.pos = "h"}
p <- rec_results %>%
  filter(satr_converge == TRUE) %>%
  ggplot(aes(x = sample_size, y = profile_ccr, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Profile Correct Classification Rate", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-prof-ccr.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-prof-ccr.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-prof-ccr.pdf")
} else {
  knitr::include_graphics("figure/pvalue-prof-ccr.png")
}
```

```{r pvalue-prof-kap, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "(ref:pvalue-kap-prof)", fig.pos = "h"}
p <- rec_results %>%
  filter(satr_converge == TRUE) %>%
  ggplot(aes(x = sample_size, y = profile_kappa, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = expression("Average Profile Cohen's "*kappa),
    fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "pvalue-prof-kap.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "pvalue-prof-kap.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/pvalue-prof-kap.pdf")
} else {
  knitr::include_graphics("figure/pvalue-prof-kap.png")
}
```

### Description of reduced parameters



## Reduction by heuristic {#heur-results}

Figure \@ref(fig:rule-converge) shows...

```{r rule-converge, fig.width = 8, fig.height = 8, out.width = "90%", fig.cap = "Convergence rates when reducing using heuristic", fig.pos = "h"}
p <- rec_results %>% 
  filter(satr_converge == FALSE) %>%
  ggplot(aes(x = sample_size, y = converge, group = model, fill = model)) +
  facet_grid(over_spec ~ attributes) +
  geom_col(width = 0.7, position = position_dodge(width = 0.7)) +
  scale_fill_OkabeIto() +
  expand_limits(y = c(0, 1)) +
  labs(x = "Sample Size", y = "Convergence Rate", fill = "Reduction\nProcess") +
  theme_bw() +
  theme(legend.position = "bottom", panel.grid.major.x = element_blank())

ggsave(filename = "rule-converge.pdf", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")
ggsave(filename = "rule-converge.png", plot = p, path = "figure", width = 8,
  height = 8, units = "in", dpi = "retina")

if (knitr::is_latex_output()) {
  knitr::include_graphics("figure/rule-converge.pdf")
} else {
  knitr::include_graphics("figure/rule-converge.png")
}
```

