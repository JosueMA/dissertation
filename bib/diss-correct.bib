@techreport{xu_fitting_2008_fix,
	address = {Princeton, NJ},
	title = {Fitting the structured general diagnostic model to {NAEP} data},
	number = {RR-08-27},
	institution = {Educational Testing Service},
	author = {Xu, X. and {von Davier}, M.},
	year = {2008}
}

@inproceedings{rojas_choosing_2012_fix,
	address = {Vancouver, British Columbia, Canada},
	title = {Choosing between general and specific cognitive diagnosis models when the sample size is small},
	author = {Rojas, G. and {de la Torre}, Jimmy and Olea, J.},
	month = apr,
	year = {2012}
}

@article{de_la_torre_dina_2009_fix,
	title = {{DINA} model and parameter estimation: {A} didactic},
	volume = {34},
	issn = {1076-9986},
	shorttitle = {{DINA} {Model} and {Parameter} {Estimation}},
	url = {http://journals.sagepub.com/doi/abs/10.3102/1076998607309474},
	doi = {10.3102/1076998607309474},
	abstract = {Cognitive and skills diagnosis models are psychometric models that have immense potential to provide rich information relevant for instruction and learning. However, wider applications of these models have been hampered by their novelty and the lack of commercially available software that can be used to analyze data from this psychometric framework. To address this issue, this article focuses on one tractable and interpretable skills diagnosis model—the DINA model—and presents it didactically. The article also discusses expectation-maximization and Markov chain Monte Carlo algorithms in estimating its model parameters. Finally, analyses of simulated and real data are presented.},
	language = {en},
	number = {1},
	journal = {Journal of Educational and Behavioral Statistics},
	author = {{de la Torre}, Jimmy},
	month = mar,
	year = {2009},
	pages = {115--130}
}

@article{de_la_torre_generalized_2011_fix,
	title = {The generalized {DINA} model framework},
	volume = {76},
	issn = {0033-3123, 1860-0980},
	url = {https://link.springer.com/article/10.1007/s11336-011-9207-7},
	doi = {10.1007/s11336-011-9207-7},
	abstract = {The G-DINA (generalized deterministic inputs, noisy “and” gate) model is a generalization of the DINA model with more relaxed assumptions. In its saturated form, the G-DINA model is equivalent to other general models for cognitive diagnosis based on alternative link functions. When appropriate constraints are applied, several commonly used cognitive diagnosis models (CDMs) can be shown to be special cases of the general models. In addition to model formulation, the G-DINA model as a general CDM framework includes a component for item-by-item model estimation based on design and weight matrices, and a component for item-by-item model comparison based on the Wald test. The paper illustrates the estimation and application of the G-DINA model as a framework using real and simulated data. It concludes by discussing several potential implications of and relevant issues concerning the proposed framework.},
	language = {en},
	number = {2},
	urldate = {2017-07-02},
	journal = {Psychometrika},
	author = {{de la Torre}, Jimmy},
	month = apr,
	year = {2011},
	pages = {179--199},
	file = {Snapshot:/Users/jakethompson/Zotero/storage/AJCJ4VMW/10.html:text/html}
}

@article{de_la_torre_empirically_2008_fix,
	title = {An empirically based method of {Q}-matrix validation for the {DINA} model: {Development} and applications},
	volume = {45},
	issn = {1745-3984},
	shorttitle = {An {Empirically} {Based} {Method} of {Q}-{Matrix} {Validation} for the {DINA} {Model}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1745-3984.2008.00069.x/abstract},
	doi = {10.1111/j.1745-3984.2008.00069.x},
	abstract = {Most model fit analyses in cognitive diagnosis assume that a Q matrix is correct after it has been constructed, without verifying its appropriateness. Consequently, any model misfit attributable to the Q matrix cannot be addressed and remedied. To address this concern, this paper proposes an empirically based method of validating a Q matrix used in conjunction with the DINA model. The proposed method can be implemented with other considerations such as substantive information about the items, or expert knowledge about the domain, to produce a more integrative framework of Q-matrix validation. The paper presents the theoretical foundation for the proposed method, develops an algorithm for its practical implementation, and provides real and simulated data applications to examine its viability. Relevant issues regarding the implementation of the method are discussed.},
	language = {en},
	number = {4},
	journal = {Journal of Educational Measurement},
	author = {{de la Torre}, Jimmy},
	month = dec,
	year = {2008},
	pages = {343--362},
	file = {Snapshot:/Users/jakethompson/Zotero/storage/WDIKXEVK/abstract.html:text/html}
}

@article{de_la_torre_note_2010_fix,
	title = {A note on the invariance of the {DINA} model parameters},
	volume = {47},
	issn = {1745-3984},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1745-3984.2009.00102.x/abstract},
	doi = {10.1111/j.1745-3984.2009.00102.x},
	abstract = {Cognitive diagnosis models (CDMs), as alternative approaches to unidimensional item response models, have received increasing attention in recent years. CDMs are developed for the purpose of identifying the mastery or nonmastery of multiple fine-grained attributes or skills required for solving problems in a domain. For CDMs to receive wider use, researchers and practitioners need to understand the basic properties of these models. The article focuses on one CDM, the deterministic inputs, noisy “and” gate (DINA) model, and the invariance property of its parameters. Using simulated data involving different attribute distributions, the article demonstrates that the DINA model parameters are absolutely invariant when the model perfectly fits the data. An additional example involving different ability groups illustrates how noise in real data can contribute to the lack of invariance in these parameters. Some practical implications of these findings are discussed.},
	language = {en},
	number = {1},
	journal = {Journal of Educational Measurement},
	author = {{de la Torre}, Jimmy and Lee, Young-Sun},
	month = mar,
	year = {2010},
	pages = {115--127},
	file = {Snapshot:/Users/jakethompson/Zotero/storage/BNBEF5BP/abstract.html:text/html}
}

@article{de_la_torre_factors_2010_fix,
	title = {Factors affecting the item parameter estimation and classification accuracy of the {DINA} model},
	volume = {47},
	issn = {1745-3984},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1745-3984.2010.00110.x/abstract},
	doi = {10.1111/j.1745-3984.2010.00110.x},
	abstract = {To better understand the statistical properties of the deterministic inputs, noisy “and” gate cognitive diagnosis (DINA) model, the impact of several factors on the quality of the item parameter estimates and classification accuracy was investigated. Results of the simulation study indicate that the fully Bayes approach is most accurate when the prior distribution matches the latent class structure. However, when the latent classes are of indefinite structure, the empirical Bayes method in conjunction with an unstructured prior distribution provides much better estimates and classification accuracy. Moreover, using empirical Bayes with an unstructured prior does not lead to extremely poor results as other prior-estimation method combinations do. The simulation results also show that increasing the sample size reduces the variability, and to some extent the bias, of item parameter estimates, whereas lower level of guessing and slip parameter is associated with higher quality item parameter estimation and classification accuracy.},
	language = {en},
	number = {2},
	journal = {Journal of Educational Measurement},
	author = {{de la Torre}, Jimmy and Hong, Yuan and Deng, Weiling},
	month = jun,
	year = {2010},
	pages = {227--249},
	file = {Snapshot:/Users/jakethompson/Zotero/storage/QEUWJPKM/abstract.html:text/html}
}

@article{de_la_torre_higher-order_2004_fix,
	title = {Higher-order latent trait models for cognitive diagnosis},
	volume = {69},
	issn = {0033-3123, 1860-0980},
	url = {https://link.springer.com/article/10.1007/BF02295640},
	doi = {10.1007/BF02295640},
	abstract = {Higher-order latent traits are proposed for specifying the joint distribution of binary attributes in models for cognitive diagnosis. This approach results in a parsimonious model for the joint distribution of a high-dimensional attribute vector that is natural in many situations when specific cognitive information is sought but a less informative item response model would be a reasonable alternative. This approach stems from viewing the attributes as the specific knowledge required for examination performance, and modeling these attributes as arising from a broadly-defined latent trait resembling theϑ of item response models. In this way a relatively simple model for the joint distribution of the attributes results, which is based on a plausible model for the relationship between general aptitude and specific knowledge. Markov chain Monte Carlo algorithms for parameter estimation are given for selected response distributions, and simulation results are presented to examine the performance of the algorithm as well as the sensitivity of classification to model misspecification. An analysis of fraction subtraction data is provided as an example.},
	language = {en},
	number = {3},
	urldate = {2017-07-20},
	journal = {Psychometrika},
	author = {{de la Torre}, Jimmy and Douglas, Jeffrey A.},
	month = sep,
	year = {2004},
	pages = {333--353},
	file = {Snapshot:/Users/jakethompson/Zotero/storage/259Q7BP9/BF02295640.html:text/html}
}

@article{de_la_torre_model_2008_fix,
	title = {Model evaluation and multiple strategies in cognitive diagnosis: {An} analysis of fraction subtraction data},
	volume = {73},
	issn = {0033-3123, 1860-0980},
	shorttitle = {Model {Evaluation} and {Multiple} {Strategies} in {Cognitive} {Diagnosis}},
	url = {https://link.springer.com/article/10.1007/s11336-008-9063-2},
	doi = {10.1007/s11336-008-9063-2},
	abstract = {This paper studies three models for cognitive diagnosis, each illustrated with an application to fraction subtraction data. The objective of each of these models is to classify examinees according to their mastery of skills assumed to be required for fraction subtraction. We consider the DINA model, the NIDA model, and a new model that extends the DINA model to allow for multiple strategies of problem solving. For each of these models the joint distribution of the indicators of skill mastery is modeled using a single continuous higher-order latent trait, to explain the dependence in the mastery of distinct skills. This approach stems from viewing the skills as the specific states of knowledge required for exam performance, and viewing these skills as arising from a broadly defined latent trait resembling the θ of item response models. We discuss several techniques for comparing models and assessing goodness of fit. We then implement these methods using the fraction subtraction data with the aim of selecting the best of the three models for this application. We employ Markov chain Monte Carlo algorithms to fit the models, and we present simulation results to examine the performance of these algorithms.},
	language = {en},
	number = {4},
	urldate = {2017-07-20},
	journal = {Psychometrika},
	author = {{de la Torre}, Jimmy and Douglas, Jeffrey A.},
	month = dec,
	year = {2008},
	pages = {595},
	file = {out.pdf:/Users/jakethompson/Zotero/storage/CXSVZJ8G/out.pdf:application/pdf;Snapshot:/Users/jakethompson/Zotero/storage/V85TBZ28/10.html:text/html}
}

@article{de_la_torre_analysis_2015_fix,
	title = {Analysis of clinical data from cognitive diagnosis modeling framework},
	issn = {0748-1756},
	url = {http://dx.doi.org/10.1177/0748175615569110},
	doi = {10.1177/0748175615569110},
	abstract = {We propose a general cognitive diagnosis model framework to diagnose mental disorders using item scores obtained from clinical measurement instruments. This framework can be used to validate the extent to which the items measure the specific disorders. The method is illustrated using data obtained with the Dutch version of Millon Clinical Multiaxial Inventory-III.},
	language = {en},
	journal = {Measurement and Evaluation in Counseling and Development},
	author = {{de la Torre}, Jimmy and van der Ark, L. Andries and Rossi, Gina},
	month = feb,
	year = {2015},
	pages = {0748175615569110},
	file = {0748175615569110.pdf:/Users/jakethompson/Zotero/storage/5V6XVMA4/0748175615569110.pdf:application/pdf;SAGE PDF Full Text:/Users/jakethompson/Zotero/storage/ZA68GWR7/de la Torre et al. - 2015 - Analysis of Clinical Data From Cognitive Diagnosis.pdf:application/pdf}
}

@article{wit_all_2012_fix,
	title = {'{All} models are wrong...': {An} introduction to model uncertainty},
	volume = {66},
	doi = {10.1111/j.1467-9574.2012.00530.x},
	abstract = {In this article, we introduce the concept of model uncertainty. We review the frequentist and Bayesian ideas underlying model selection, which serve as an introduction to the rest of this special issue on 'All models are wrong...', a workshop under the same name was held in March 2011 in Groningen to critically examined the field of statistical model selection methods over the past 40 years. We briefly introduce the philosophical debate that is concerned with model selection. We present the results of a questionnaire that was distributed under the participants of the workshop, showing that the field has not yet reached a comforting consensus and is still in full swing.},
	number = {3},
	journal = {Statistica Neerlandica},
	author = {Wit, Ernst and {van den Heuvel}, Edwin and Romeijn, Jan-Willem},
	year = {2012},
	pages = {217--236}
}
